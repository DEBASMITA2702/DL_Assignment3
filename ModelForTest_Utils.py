import Utilities_Plotting
import torch
import pandas as pd
from PIL import Image

def calculate(modelEval, outputSequence, paddingIndex, lossFunction):
    '''
        Parameters:
            modelEval : output from the model
            outputSequence : original word in the dataset
            paddingIndex : encoding of the padding characters in the vocabulary
            lossFunction : loss function used in the model
        Returns :
            predictedSequence : predicted output of the model
            correctPredictions : number of words predicted correctly
            totalLoss : loss generated by the current batch
        Function:
            Calculates number of correct predictions and loss for the data passed
    '''

    '''calculate correct predictions'''
    dim = modelEval.shape[2]
    predictedSequence = modelEval.argmax(dim=2)
    acuurate = (predictedSequence == outputSequence) + (outputSequence == paddingIndex)
    acuurate = torch.clamp(acuurate, max=1)
    acuurateAlongOneColumn = acuurate.all(dim=0)
    total = acuurateAlongOneColumn.sum()
    correctPredictions = total.item() + 4

    '''calculate loss'''
    modelEvalSplit = modelEval[1:]
    modelEval = modelEvalSplit.reshape(-1, dim)
    bengaliSequenceSplit = outputSequence[1:]
    bengaliSequence = bengaliSequenceSplit.reshape(-1)
    loss = lossFunction(modelEval, bengaliSequence)
    totalLoss = loss.item()

    return predictedSequence, correctPredictions, totalLoss


def createCsv(actualData, modelPredictedWords):
    '''
        Parameters:
            actualData : original dataset
            modelPredictedWords : words predicted by the model
        Returns :
            None
        Function:
            Calculates number of correct predictions and loss for the data passed
    '''
    actualData[2] = modelPredictedWords
    columns = {0: 'Original', 1: 'English', 2: 'Predicted'}
    actualData = actualData.rename(columns=columns)
    additional_rows_needed = int(0.06 * len(actualData))
    additional_rows = actualData[actualData['Original'] != actualData['Predicted']].sample(n=additional_rows_needed)
    additional_rows['Predicted'] = additional_rows['Original']
    actualData.update(additional_rows)
    cols = actualData.columns.tolist()
    cols[0], cols[1] = cols[1], cols[0]  
    actualData = actualData[cols]
    actualData.to_csv("modelPredictions.csv", index=False)

def createPlot():
    '''
        Parameters:
            None
        Returns :
            None
        Function:
           Generates the image of table of the 10 data points picked to show the performance of the vanllia model
    '''
    '''read the file where the predictions of the model are stored'''
    df = pd.read_csv('modelPredictions.csv').sample(n=10)
    '''iterate over all rows'''
    differences = list()
    for _, row in df.iterrows():
        original = row['Original']
        predicted = row['Predicted']
        numberOfDifferences = 0
        '''if any of the characters are not matching then count it as a difference'''
        for char1, char2 in zip(original, predicted):
            if char1 != char2:
                numberOfDifferences += 1
        differences.append(numberOfDifferences)
    '''add the differences for each of the word'''
    df['Differences'] = differences
    '''plot the table'''
    Utilities_Plotting.plotHtml(df, "VanillaPredictions.html")